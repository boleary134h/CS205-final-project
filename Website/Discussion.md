# Discussion

Our goal was to parallelize the tast of producing text summaries of a large set of documents, such as the CNN-DailyMail dataset. We designed our methodology to include parallelization in three ways: using multiprocessing for the text pre-processing, using MPI for task parallelization, and using OpenMP for loop parallelization.

We find that we can achieve close to linear speed-up with MPI task parallelism, which we believe is because there is little communication overhead needed in the AWS cluster. However, the loop parallelism with OpenMP has little effect as the execution time with and without OpenMP is similar. We attribute it to 2 potential reasons. The first is that our current model is more data intensive than compute intensive. The second reason is that the documents in the CNN-DailyMail dataset are only 20-30 sentences long. With these short documents, the serial textrank is already quite fast. Given that we find our process to be more big data intensive than big compute intensive, we acknowledge that other methodologies could have been used, such as PySpark. However, if we use summarization datasets with much longer text, such as [arxiv](https://github.com/armancohan/long-summarization), we think the hybrid MPI-OpenMP could see more performance gains than we document here.