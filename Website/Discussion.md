# Discussion
We find that we could get close to linear speed-up with MPI task parallelism. We think it is because there is almost no communication overhead. However, loop parallelism with OpenMP has little effect. We attribute it to 2 potential reasons. The first is that our current model is more data intensive than compute intensive. The second reason is that Documents were only 20-30 sentences long, serial textrank is already quite fast. To make OpenMp more effective, we could use pyspark. Besides, if we use summarization datasets with longer text such as [arxiv](https://github.com/armancohan/long-summarization), hybrid MPI-OpenMP could see more performance gains.